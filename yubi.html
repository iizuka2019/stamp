<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>両手指認識ハンドジェスチャープロトタイプ</title>
    <style>
        /* CSSは変更なし */
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f0f4f8;
            color: #333;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
        }
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            margin: 0 auto;
            overflow: hidden;
            border-radius: 8px;
        }
        #video {
            width: 100%;
            height: auto;
            transform: scaleX(-1); /* ミラー表示 */
            background-color: #333;
        }
        #canvas {
            position: absolute;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1); /* ミラー表示 */
        }
        .controls {
            display: flex;
            justify-content: center;
            margin: 20px 0;
            gap: 15px;
        }
        button {
            padding: 10px 15px;
            background-color: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #2980b9;
        }
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
        }
        .status {
            margin-top: 20px;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border-left: 5px solid #3498db;
        }
        .gesture-info {
            display: flex;
            justify-content: space-around;
            margin-top: 20px;
        }
        .hand-info {
            width: 45%;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border-left: 5px solid #27ae60;
        }
        .loading {
            text-align: center;
            padding: 20px;
            font-size: 18px;
            color: #7f8c8d;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>両手指認識ハンドジェスチャープロトタイプ</h1>
        
        <div class="controls">
            <button id="startBtn" disabled>カメラ開始</button> <!-- 初期状態は無効化 -->
            <button id="stopBtn" disabled>停止</button>
        </div>
        
        <div class="video-container">
            <video id="video" playsinline style="display: none;"></video> <!-- camera_utilsが制御するので非表示でもOK -->
            <canvas id="canvas"></canvas>
        </div>
        
        <div id="loading" class="loading">MediaPipeモデルを読み込み中...</div>
        
        <div class="gesture-info">
            <div class="hand-info">
                <h3>左手情報</h3>
                <div id="leftHandInfo">未検出</div>
                <div id="leftHandGesture">ジェスチャー: なし</div>
            </div>
            <div class="hand-info">
                <h3>右手情報</h3>
                <div id="rightHandInfo">未検出</div>
                <div id="rightHandGesture">ジェスチャー: なし</div>
            </div>
        </div>
        
        <div class="status">
            <h3>状態:</h3>
            <div id="status">カメラが停止しています</div>
        </div>
    </div>

    <!-- MediaPipe Hands & Camera Utils-->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469240/hands.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3/drawing_utils.js" crossorigin="anonymous"></script>

    <script>
        // DOM要素
        const videoElement = document.getElementById('video');
        const canvasElement = document.getElementById('canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        const loadingDiv = document.getElementById('loading');
        const leftHandInfo = document.getElementById('leftHandInfo'); // ユーザーから見て左手
        const rightHandInfo = document.getElementById('rightHandInfo'); // ユーザーから見て右手
        const leftHandGesture = document.getElementById('leftHandGesture');
        const rightHandGesture = document.getElementById('rightHandGesture');
        
        let hands; // handsModel ではなく hands
        let camera;
        let isRunning = false;
        // `stream` 変数は camera_utils を使う場合、直接管理する必要は薄れます

        function onResults(results) {
            // キャンバスのサイズをビデオのサイズに合わせる (初回または変更時)
            if (canvasElement.width !== results.image.width) {
                canvasElement.width = results.image.width;
            }
            if (canvasElement.height !== results.image.height) {
                canvasElement.height = results.image.height;
            }

            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            
            // 入力映像をキャンバスに描画 (ミラーリングされた映像が渡ってくる)
            // canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

            let userLeftHandLandmarks = null;
            let userRightHandLandmarks = null;

            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                for (let i = 0; i < results.multiHandLandmarks.length; i++) {
                    const landmarks = results.multiHandLandmarks[i];
                    // camera_utils を使うと、results.image は既にミラーリングされている前提。
                    // handedness もカメラから見た左右。
                    // UI上の「左手」「右手」はユーザーから見たものなので、
                    // CSSで video と canvas を transform: scaleX(-1) している場合、
                    // MediaPipe の 'Left' がユーザーの右手、'Right' がユーザーの左手になる。
                    const cameraHandedness = results.multiHandedness[i].label;
                    const userHandedness = cameraHandedness === 'Left' ? 'Right' : 'Left';

                    // 描画: ユーザーの左手を緑、右手を赤 (これはUI上の表示に合わせる)
                    const drawColor = userHandedness === 'Left' ? '#00FF00' : '#FF0000';
                    
                    // drawing_utils を使用
                    drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {color: drawColor, lineWidth: 3});
                    drawLandmarks(canvasCtx, landmarks, {color: drawColor, lineWidth: 1, radius: 5});

                    if (userHandedness === 'Left') {
                        userLeftHandLandmarks = landmarks;
                    } else { // userHandedness === 'Right'
                        userRightHandLandmarks = landmarks;
                    }
                }
            }

            // 左手情報 (ユーザーから見て左手)
            if (userLeftHandLandmarks) {
                const gesture = detectGesture(userLeftHandLandmarks);
                leftHandInfo.textContent = `検出: ${userLeftHandLandmarks.length}点`;
                leftHandGesture.textContent = `ジェスチャー: ${gesture}`;
            } else {
                leftHandInfo.textContent = '未検出';
                leftHandGesture.textContent = 'ジェスチャー: なし';
            }
            
            // 右手情報 (ユーザーから見て右手)
            if (userRightHandLandmarks) {
                const gesture = detectGesture(userRightHandLandmarks);
                rightHandInfo.textContent = `検出: ${userRightHandLandmarks.length}点`;
                rightHandGesture.textContent = `ジェスチャー: ${gesture}`;
            } else {
                rightHandInfo.textContent = '未検出';
                rightHandGesture.textContent = 'ジェスチャー: なし';
            }
            canvasCtx.restore();
        }
        
        // MediaPipe Handsの初期化とカメラ設定
        async function initializeMediaPipe() {
            hands = new Hands({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469240/${file}`;
                }
            });
            
            hands.setOptions({
                maxNumHands: 2,
                modelComplexity: 1,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5,
                selfieMode: true // ★重要: camera_utilsと組み合わせる場合、入力が反転されるのでtrue
            });
            
            hands.onResults(onResults);
            
            camera = new Camera(videoElement, {
                onFrame: async () => {
                    // isRunning フラグは camera.start() / camera.stop() で制御するので不要
                    await hands.send({image: videoElement});
                },
                width: 640, // canvasの表示サイズに合わせて調整
                height: 480
            });

            loadingDiv.style.display = 'none';
            statusDiv.textContent = 'モデル準備完了！カメラを開始してください。';
            startBtn.disabled = false; // 準備完了でボタン有効化
        }
        
        // ジェスチャーの検出（変更なし）
        function detectGesture(landmarks) {
            const fingertips = [4, 8, 12, 16, 20];
            const secondJoints = [3, 7, 11, 15, 19];
            
            let extendedFingers = 0;
            for (let i = 1; i < fingertips.length; i++) {
                const fingertip = landmarks[fingertips[i]];
                const mcpJoint = landmarks[fingertips[i]-3]; // MCP関節 (例: 人差し指なら5)
                if (fingertip.y < mcpJoint.y) { // Y座標は上が小さい
                    extendedFingers++;
                }
            }
            
            const thumbTip = landmarks[fingertips[0]]; // 4
            const thumbMcp = landmarks[2]; // 2 (親指のMCP)
            // 親指が開いているか (x座標で判定する単純な例)
            // selfieMode: true のため、x座標の大小関係が通常と逆になることに注意
            // 画面左がx大、右がx小
            // 通常、親指が外側に開くと、親指の先端のxは人差し指の付け根のxより小さい(カメラ視点)
            // selfieModeだとこれが逆になる。
            // または、親指の先端が親指のMCP関節よりy座標が小さい（上に伸びている）
            if (thumbTip.y < thumbMcp.y ) { // 縦方向の伸びで判定
                 extendedFingers++;
            }
            
            if (extendedFingers === 5) return '開いた手';
            if (extendedFingers === 0) return '握りこぶし';
            if (extendedFingers === 2) {
                // 人差し指と中指が伸びているか
                const indexTipY = landmarks[8].y;
                const indexMcpY = landmarks[5].y;
                const middleTipY = landmarks[12].y;
                const middleMcpY = landmarks[9].y;
                if (indexTipY < indexMcpY && middleTipY < middleMcpY) return 'ピース';
            }
            if (extendedFingers === 1) {
                const indexTipY = landmarks[8].y;
                const indexMcpY = landmarks[5].y;
                if (indexTipY < indexMcpY) return '指差し';
            }
            return `指 ${extendedFingers} 本`;
        }
        
        // 検出を開始
        async function startDetection() {
            if (isRunning) return;
            
            try {
                await camera.start(); // camera_utils の start を呼ぶ
                isRunning = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                statusDiv.textContent = '検出中...両手を画面に向けてください';
            } catch (error) {
                console.error('検出の開始に失敗しました:', error);
                isRunning = false;
                statusDiv.textContent = 'エラー: 検出の開始に失敗しました。';
            }
        }
        
        // 検出を停止
        function stopDetection() {
            if (!isRunning && !camera) return; // cameraが未初期化の場合もある
            
            if (camera) { // cameraが初期化されていればstopを試みる
                // camera.stop(); // camera_utils には明示的な stop() がないことが多い
                               // ストリームの停止で代用、または onFrame の処理を止める
                // 代わりにビデオストリームを止める
                const stream = videoElement.srcObject;
                if (stream) {
                    const tracks = stream.getTracks();
                    tracks.forEach(track => track.stop());
                    videoElement.srcObject = null;
                }
            }
            
            isRunning = false;
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            startBtn.disabled = false;
            stopBtn.disabled = true;
            statusDiv.textContent = '停止しました';
            leftHandInfo.textContent = '未検出';
            rightHandInfo.textContent = '未検出';
            leftHandGesture.textContent = 'ジェスチャー: なし';
            rightHandGesture.textContent = 'ジェスチャー: なし';

            // 再度開始できるように、モデルを再初期化するか、カメラを再設定する必要がある場合がある
            // ここでは単純にUIをリセットするのみ
        }
        
        // イベントリスナーを設定
        startBtn.addEventListener('click', startDetection);
        stopBtn.addEventListener('click', stopDetection);
        
        // ページ読み込み時にモデルを読み込む
        window.addEventListener('load', async () => {
            try {
                await initializeMediaPipe();
            } catch (error) {
                console.error("初期化エラー:", error);
                loadingDiv.textContent = '初期化エラーが発生しました。コンソールを確認してください。';
            }
        });
    </script>
</body>
</html>
